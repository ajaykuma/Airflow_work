#Creating dependency between dags based on file ie using a DS
--create producer

my_file = Dataset("/home/hdu/airflow/configs/sample.txt")
# default_args = {

#     'owner': 'hdu',
#     'retries': 5,
#     'retry_delay': timedelta(minutes=5)
# }

with DAG(
    dag_id = "producer",
    schedule='@daily',
    start_date=datetime(2024,11,20),
    catchup=False
):

    @task(outlets=[my_file])
    def the_task_update():
        with open(my_file.uri, "a+") as f:
            f.write("producer update")

    the_task_update()

Note** Needed to run first for other dag ie consumer to get successfully run

--create consumer
my_file = Dataset("/home/hdu/airflow/configs/sample.txt")
# default_args = {

#     'owner': 'hdu',
#     'retries': 5,
#     'retry_delay': timedelta(minutes=5)
# }

with DAG(
    dag_id = "consumer",
    schedule=[my_file],
    start_date=datetime(2024,11,20),
    #dagrun_timeout=timedelta(seconds=10),  
    catchup=False
):

    
    # @task(outlets=[my_file])
    @task()
    def the_task_read():
        with open(my_file.uri, "r") as f:
            print(f.read())

    the_task_read()

--run consumer and this will show no execution or on wait till producer runs.
--trigger producer and check if consumer then runs.

=============================
--Sensor Operator examples

--import
from airflow.providers.http.sensors.http import HttpSensor
from airflow.providers.http.operators.http import SimpleHttpOperator

--tasks

tk_brk = BashOperator(
	task_id = 'tk_brk',
	bash_command = 'sleep 10'
	)

is_api_available = HttpSensor(
	task_id = 'is_api_available',
	http_conn_id = 'user_api',
	endpoint = '/api',
	#response_check=lambda response: "mydata" in response.txt,
	poke_interval = 5,
	timeout=20
	)

extract_user = SimpleHttpOperator(
	task_id = 'extract_user',
	http_conn_id = 'user_api',
	endpoint = '/api',
	method = 'GET',
	response_filter = lambda response:json.loads(response.text),
	log_response = True
	)

file_chk = FileSensor(
	task_id = "is_file_avai",
	fs_conn_id = "file_path",
	filepath="mydata.csv",
	poke_interval = 5,
	timeout=20
	)

Note** Create file connection
connection name : fs_conn_id
conn type: File(path)
Extras: {"path":"/<filepath>"}
==========
	
